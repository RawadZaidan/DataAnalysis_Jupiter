{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prehook\n",
    "\n",
    "prehook.execute_prehook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hook\n",
    "import prehook\n",
    "import database_handler\n",
    "import lookups\n",
    "import datetime\n",
    "\n",
    "db_session = database_handler.create_connection()\n",
    "# hook.create_etl_checkpoint(db_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook.return_lookup_items_as_dict(lookups.IncrementalField)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\96171\\Desktop\\SE_Factory\\Week7\\ETL\\ETL_Project_2\\database_handler.py:46: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  return_dataframe = pd.read_sql_query(con= db_session, sql= file_executor)\n"
     ]
    }
   ],
   "source": [
    "import hook\n",
    "import prehook\n",
    "import database_handler\n",
    "import lookups\n",
    "import datetime\n",
    "\n",
    "db_session = database_handler.create_connection()\n",
    "etl_date = datetime.datetime(1900,1,1)\n",
    "#SourceName is schema name\n",
    "source_name = lookups.SourceName.DVD_RENTAL.value\n",
    "#This will get you a list of tables inside this schema that are mentioned in SQLTablesToReplicate\n",
    "tables = prehook.return_tables_by_schema(source_name)\n",
    "#This will return \n",
    "incremental_date_dict = hook.return_lookup_items_as_dict(lookups.IncrementalField)\n",
    "# for table in tables:\n",
    "staging_query = f\"\"\"\n",
    "        SELECT * FROM {source_name}.{tables[0]} WHERE {incremental_date_dict.get(tables[0])} >= '{etl_date}'\n",
    "\"\"\" \n",
    "staging_df = database_handler.return_data_as_df(db_session= db_session, input_type= lookups.InputTypes.SQL, file_executor= staging_query)\n",
    "dst_table = f\"stg_{source_name}_{tables[0]}\"\n",
    "insert_stmt = database_handler.return_insert_into_sql_statement_from_df(staging_df, 'dw_reporting', dst_table)\n",
    "for insert in insert_stmt:\n",
    "        database_handler.execute_query(db_session=db_session, query= insert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
